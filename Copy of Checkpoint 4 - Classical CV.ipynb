{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1P_RO1jdv4PHeCb2uvtRyFntorWC8h0KV","timestamp":1759091206980}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ðŸŽ¥ Checkpoint 4 - Classical CV: Counting Yellow Obstacles\n","\n","## ðŸ“Œ Goal\n","You are given a video containing multiple objects of different colors.  \n","Your task is to **detect how many yellow obstacles are present in each frame** and output this as an array.\n","\n","This assignment will help you practice **color-based segmentation, video processing, using Google Colab, and working through some corner cases** in computer vision.\n","\n","---\n"],"metadata":{"id":"U_K-s2IXhYKf"}},{"cell_type":"markdown","source":["## Step 0: Import Required Libraries"],"metadata":{"id":"4BDrwU8XJZ54"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt"],"metadata":{"id":"kYXddi6TJd_d","executionInfo":{"status":"ok","timestamp":1759091236736,"user_tz":240,"elapsed":70,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Step 1: Mount your G Drive and access the videos"],"metadata":{"id":"s-J3iFRaDuvk"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0VH5afWoD43J","executionInfo":{"status":"ok","timestamp":1759091309431,"user_tz":240,"elapsed":19209,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}},"outputId":"31588249-bf4f-441f-8562-554b7247735c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Now, use the file explorer on the left to find the path to the videos for this task.\n","\n","They should be in your UMARV Shared Drive called `STUDENT-Robotics | UMARV` at `2025-2026/CV Onboarding`"],"metadata":{"id":"fscyKuJuEOCX"}},{"cell_type":"code","source":["# TODO\n","train_video_path = \"/content/drive/Shareddrives/STUDENT-Robotics | UMARV/2025-2026/CV Onboarding/Train-Checkpoint-CV.mp4\"\n","test_video_path = \"/content/drive/Shareddrives/STUDENT-Robotics | UMARV/2025-2026/CV Onboarding/Test-Checkpoint-CV.mp4\""],"metadata":{"id":"96tR9pQbFIRc","executionInfo":{"status":"ok","timestamp":1759093168336,"user_tz":240,"elapsed":41,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Process the video\n","\n","Read the frames of the train video using the OpenCV Fundamentals Onboarding section: [link](https://github.com/umigv/CV-Onboarding/blob/main/3_Programming/3_opencv.md)"],"metadata":{"id":"qAL17GZ4Fu3V"}},{"cell_type":"code","source":["cap = cv2.VideoCapture(\"video.mp4\")\n","\n","while cap.isOpened():\n","  ret, frame = cap.read()\n","  if not ret:\n","        break\n","\n","  cv2.imshow(\"Frame\", frame)   # show each video frame\n","\n","  if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","pass"],"metadata":{"id":"l8nAfSoNII9U","executionInfo":{"status":"ok","timestamp":1759093387734,"user_tz":240,"elapsed":35,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Get HSV range for Yellow\n","\n","Use this stack overflow post to identify the HSV upper and lower limits for yellow: [link](https://stackoverflow.com/a/48367205)\n","\n","The example snippet here might be helpful! [Link](https://github.com/umigv/CV-Onboarding/blob/main/4_Classical_CV/1_hsv_filtering.md)\n","\n","The V values have already been put in for you. You need to fill the H and S values.\n","\n","<details>\n","<summary>Hint 1</summary>\n","Are you seeing only small patches of yellow near the obstacles, but not the whole obstacle in your mask? Try decreasing the lower limit of H further to include brownish hues as well.\n","</details>\n","\n","<details>\n","<summary>Hint 2</summary>\n","Are you seeing the yellow lane lines in your mask? Try increasing the upper limit of S further to only look at darker yellows.\n","</details>\n","\n","<details>\n","<summary>Final Hint!</summary>\n","<ul>\n","<li>Range for H: (5,40) </li>\n","<li>Range for S: (100,255) </li>\n","</ul>\n","</details>"],"metadata":{"id":"TD_pG-edC7QP"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"SxljBnKNhUiu","executionInfo":{"status":"ok","timestamp":1759093571934,"user_tz":240,"elapsed":16,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}}},"outputs":[],"source":["# TODO\n","lower_yellow = np.array([20, 100, 20])   # lower bound [H, S, V]\n","upper_yellow = np.array([30, 255, 255])  # upper bound [H, S, V]"]},{"cell_type":"markdown","source":["## Step 4: Core Logic for Yellow Obstacle Detection\n","\n","Use HSV filtering [(link)](https://github.com/umigv/CV-Onboarding/blob/main/4_Classical_CV/1_hsv_filtering.md) and Contours [(link)](https://github.com/umigv/CV-Onboarding/blob/main/4_Classical_CV/2_contours.md) to identify the yellow obstacles and count how many there are in each frame!\n","\n","This list of features will be useful in this task (especially **Contour Area**): [Contour Features](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)\n","\n","<details>\n","<summary>Hint 1</summary>\n","You should be able to copy paste the code for `hsv = ...` and `mask = ...` from the onboarding docs for HSV filtering.\n","</details>\n","\n","<details>\n","<summary>Hint 2</summary>\n","You should be able to copy paste the code for contours for `contours = ...` from the onboarding docs for contours.\n","</details>\n","\n","<details>\n","<summary>Hint 3</summary>\n","You should be able to iterate over `contours`, which is a list of contours. Use `cv2.contourArea(cnt)` to know its area. Thresholding area to find significant contours will help! That is, `if cv2.contourArea(cnt) > THRESHOLD`, do something.\n","</details>\n","\n","<details>\n","<summary>Final Hint!</summary>\n","`if cv2.contourArea(c) > 1100:`, increment your counter for yellow obstacles.\n","</details>"],"metadata":{"id":"iC1bjrNOIqVO"}},{"cell_type":"code","source":["from google.colab.patches import cv_imshow\n","\n","# TODO\n","def count_yellow_obstacles(frame):\n","  # 1. Apply HSV Filtering on the frame to obtain a mask of yellow objects\n","  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","  lower_yellow = np.array([20, 100, 20])\n","  upper_yellow = np.array([30, 255, 255])\n","  mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n","\n","  # 2. Use Contours to identify these objects in the mask (remember, all other objects will be masked out!)\n","  contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","  # 3. Use some logic (like the area or shape of the contour to detect obstacles)\n","  yellow_obstacle_count = 0\n","\n","  min_obstacle_area = 1100\n","\n","\n","  if contours:\n","      for contour in contours:\n","\n","          if isinstance(contour, np.ndarray):\n","              area = cv2.contourArea(contour)\n","              if area > min_obstacle_area:\n","                  yellow_obstacle_count += 1\n","\n","\n","  # Visualization\n","  frame_resized = cv2.resize(frame, (300, 300))\n","  mask_resized  = cv2.resize(cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR), (300, 300))\n","  side_by_side  = np.hstack((frame_resized, mask_resized))\n","  cv_imshow(side_by_side)\n","\n","  # 4. Return a count of yellow obstacles identified\n","  return yellow_obstacle_count"],"metadata":{"id":"2vheZwkgJKXT","executionInfo":{"status":"ok","timestamp":1759094628811,"user_tz":240,"elapsed":30,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Step 5: Integrate everything into `main()`\n","\n","In any program, the `main()` or `run()` function serves as the entry point to the rest of the functionality. So that's what we'll implement as well."],"metadata":{"id":"OdyR_hwOLmGM"}},{"cell_type":"code","source":["def main(video_path=train_video_path):\n","  cap = cv2.VideoCapture(video_path)\n","  yellow_obstacle_count_list = []\n","  target_fps = 5\n","  input_fps = cap.get(cv2.CAP_PROP_FPS)\n","  frame_interval = int(round(input_fps / target_fps))\n","\n","  frame_count = 0\n","  while cap.isOpened():\n","      ret, frame = cap.read()\n","      if not ret:\n","          break\n","\n","      if frame_count % frame_interval == 0:\n","        yellow_obstacle_count = count_yellow_obstacles(frame)\n","        yellow_obstacle_count_list.append(yellow_obstacle_count)\n","\n","      frame_count += 1\n","\n","  print(len(yellow_obstacle_count_list))\n","  print(yellow_obstacle_count_list)\n","  plt.plot(yellow_obstacle_count_list)\n","\n","\n","main()\n","\n"],"metadata":{"id":"d5pOvmnuL8Oo","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1QiCLkNLFZZfPapctga9X3tdbLlUBd8c8"},"executionInfo":{"status":"ok","timestamp":1759094682472,"user_tz":240,"elapsed":36678,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}},"outputId":"b3b43b78-1ab6-4367-8471-077953078725"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Step 6: Test your algorithm on the Test Video"],"metadata":{"id":"FEZi95YepgCF"}},{"cell_type":"code","source":["main(video_path=test_video_path)"],"metadata":{"id":"z-VuS9J3piXB","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1omen73GG1mDXwLiPGt40Myxj65cGbdYy"},"executionInfo":{"status":"ok","timestamp":1759094703931,"user_tz":240,"elapsed":21212,"user":{"displayName":"Joshua Kim","userId":"12900018952136337946"}},"outputId":"0c8e8103-b6cc-4589-ed10-7ac4df3682a5"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}