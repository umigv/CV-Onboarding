{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1P_RO1jdv4PHeCb2uvtRyFntorWC8h0KV","timestamp":1760735726075}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ðŸŽ¥ Checkpoint 4 - Classical CV: Counting Yellow Obstacles\n","\n","## ðŸ“Œ Goal\n","You are given a video containing multiple objects of different colors.  \n","Your task is to **detect how many yellow obstacles are present in each frame** and output this as an array.\n","\n","This assignment will help you practice **color-based segmentation, video processing, using Google Colab, and working through some corner cases** in computer vision.\n","\n","---\n"],"metadata":{"id":"U_K-s2IXhYKf"}},{"cell_type":"markdown","source":["## Step 0: Import Required Libraries"],"metadata":{"id":"4BDrwU8XJZ54"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt"],"metadata":{"id":"kYXddi6TJd_d","executionInfo":{"status":"ok","timestamp":1760736844428,"user_tz":240,"elapsed":13,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Step 1: Mount your G Drive and access the videos"],"metadata":{"id":"s-J3iFRaDuvk"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0VH5afWoD43J","executionInfo":{"status":"ok","timestamp":1760736846199,"user_tz":240,"elapsed":687,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}},"outputId":"0879c288-1661-4512-a41f-9414468bd560"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Now, use the file explorer on the left to find the path to the videos for this task.\n","\n","They should be in your UMARV Shared Drive called `STUDENT-Robotics | UMARV` at `2025-2026/CV Onboarding`"],"metadata":{"id":"fscyKuJuEOCX"}},{"cell_type":"code","source":["# TODO\n","train_video_path = \"/content/drive/Shareddrives/STUDENT-Robotics | UMARV/2025-2026/CV Onboarding/Test-Checkpoint-CV.mp4\"\n","test_video_path = \"/content/drive/Shareddrives/STUDENT-Robotics | UMARV/2025-2026/CV Onboarding/Train-Checkpoint-CV.mp4\""],"metadata":{"id":"96tR9pQbFIRc","executionInfo":{"status":"ok","timestamp":1760736846718,"user_tz":240,"elapsed":5,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Process the video\n","\n","Read the frames of the train video using the OpenCV Fundamentals Onboarding section: [link](https://github.com/umigv/CV-Onboarding/blob/main/3_Programming/3_opencv.md)"],"metadata":{"id":"qAL17GZ4Fu3V"}},{"cell_type":"code","source":["cap = cv2.VideoCapture(\"video.mp4\")\n","\n","while cap.isOpened():\n","  ret, frame = cap.read();\n","  if not ret:\n","        break\n","\n","  cv2.imshow(\"Frame\", frame)\n","\n","  if cv2.waitKey(1) & 0xFF == ord('q'):\n","      break\n","  cap.release()\n","  cv2.destroyAllWindows()\n","  pass"],"metadata":{"id":"l8nAfSoNII9U","executionInfo":{"status":"ok","timestamp":1760736031746,"user_tz":240,"elapsed":16,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Get HSV range for Yellow\n","\n","Use this stack overflow post to identify the HSV upper and lower limits for yellow: [link](https://stackoverflow.com/a/48367205)\n","\n","The example snippet here might be helpful! [Link](https://github.com/umigv/CV-Onboarding/blob/main/4_Classical_CV/1_hsv_filtering.md)\n","\n","The V values have already been put in for you. You need to fill the H and S values.\n","\n","<details>\n","<summary>Hint 1</summary>\n","Are you seeing only small patches of yellow near the obstacles, but not the whole obstacle in your mask? Try decreasing the lower limit of H further to include brownish hues as well.\n","</details>\n","\n","<details>\n","<summary>Hint 2</summary>\n","Are you seeing the yellow lane lines in your mask? Try increasing the upper limit of S further to only look at darker yellows.\n","</details>\n","\n","<details>\n","<summary>Final Hint!</summary>\n","<ul>\n","<li>Range for H: (5,40) </li>\n","<li>Range for S: (100,255) </li>\n","</ul>\n","</details>"],"metadata":{"id":"TD_pG-edC7QP"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"SxljBnKNhUiu","executionInfo":{"status":"ok","timestamp":1760737257506,"user_tz":240,"elapsed":10,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}}},"outputs":[],"source":["lower_yellow = np.array([5, 40, 20])   # lower bound [H, S, V]\n","upper_yellow = np.array([40, 255, 255])  # upper bound [H, S, V]"]},{"cell_type":"markdown","source":["## Step 4: Core Logic for Yellow Obstacle Detection\n","\n","Use HSV filtering [(link)](https://github.com/umigv/CV-Onboarding/blob/main/4_Classical_CV/1_hsv_filtering.md) and Contours [(link)](https://github.com/umigv/CV-Onboarding/blob/main/4_Classical_CV/2_contours.md) to identify the yellow obstacles and count how many there are in each frame!\n","\n","This list of features will be useful in this task (especially **Contour Area**): [Contour Features](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)\n","\n","<details>\n","<summary>Hint 1</summary>\n","You should be able to copy paste the code for `hsv = ...` and `mask = ...` from the onboarding docs for HSV filtering.\n","</details>\n","\n","<details>\n","<summary>Hint 2</summary>\n","You should be able to copy paste the code for contours for `contours = ...` from the onboarding docs for contours.\n","</details>\n","\n","<details>\n","<summary>Hint 3</summary>\n","You should be able to iterate over `contours`, which is a list of contours. Use `cv2.contourArea(cnt)` to know its area. Thresholding area to find significant contours will help! That is, `if cv2.contourArea(cnt) > THRESHOLD`, do something.\n","</details>\n","\n","<details>\n","<summary>Final Hint!</summary>\n","`if cv2.contourArea(c) > 1100:`, increment your counter for yellow obstacles.\n","</details>"],"metadata":{"id":"iC1bjrNOIqVO"}},{"cell_type":"code","source":["from google.colab.patches import cv_imshow\n","\n","# TODO\n","def count_yellow_obstacles(frame):\n","  # 1. Apply HSV Filtering on the frame to obtain a mask of yellow objects\n","  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","  mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n","\n","  # 2. Use Contours to identify these objects in the mask (remember, all other objects will be masked out!)\n","  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","  _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n","  contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","  # 3. Use some logic (like the area or shape of the contour to detect obstacles)\n","  yellow_obstacle_count = 0\n","  for cnt in contours:\n","    if cv2.contourArea(cnt) > 1100:\n","      yellow_obstacle_count += 1\n","  # Visualization\n","  frame_resized = cv2.resize(frame, (300, 300))\n","  mask_resized  = cv2.resize(cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR), (300, 300))\n","  side_by_side  = np.hstack((frame_resized, mask_resized))\n","  cv_imshow(side_by_side)\n","\n","\n","  # 4. Return a count of yellow obstacles identified\n","  return yellow_obstacle_count"],"metadata":{"id":"2vheZwkgJKXT","executionInfo":{"status":"ok","timestamp":1760737122865,"user_tz":240,"elapsed":14,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Step 5: Integrate everything into `main()`\n","\n","In any program, the `main()` or `run()` function serves as the entry point to the rest of the functionality. So that's what we'll implement as well."],"metadata":{"id":"OdyR_hwOLmGM"}},{"cell_type":"code","source":["def main(video_path=train_video_path):\n","  cap = cv2.VideoCapture(video_path)\n","  yellow_obstacle_count_list = []\n","  target_fps = 5\n","  input_fps = cap.get(cv2.CAP_PROP_FPS)\n","  frame_interval = int(round(input_fps / target_fps))\n","\n","  frame_count = 0\n","  while cap.isOpened():\n","      ret, frame = cap.read()\n","      if not ret:\n","          break\n","\n","      if frame_count % frame_interval == 0:\n","        yellow_obstacle_count = count_yellow_obstacles(frame)\n","        yellow_obstacle_count_list.append(yellow_obstacle_count)\n","\n","      frame_count += 1\n","\n","  print(len(yellow_obstacle_count_list))\n","  print(yellow_obstacle_count_list)\n","  plt.plot(yellow_obstacle_count_list)\n","\n","\n","main()\n","\n"],"metadata":{"id":"d5pOvmnuL8Oo","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pGLk1Cd854UCUBY0jnTdYI4nWeC7Udds"},"executionInfo":{"status":"ok","timestamp":1760737301492,"user_tz":240,"elapsed":39112,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}},"outputId":"abf116e7-3446-4a4c-e7fd-a88e2b59ca73"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Step 6: Test your algorithm on the Test Video"],"metadata":{"id":"FEZi95YepgCF"}},{"cell_type":"code","source":["main(video_path=test_video_path)"],"metadata":{"id":"z-VuS9J3piXB","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"11kbgJ_OHFff8LNVljmt4BVVZymXB4goA"},"executionInfo":{"status":"ok","timestamp":1760737338769,"user_tz":240,"elapsed":32840,"user":{"displayName":"Lindsay Huynh","userId":"14272953550704157827"}},"outputId":"362ac147-b22b-4ffd-e94f-45d60650bfe9"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}