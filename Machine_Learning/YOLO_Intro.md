For last year's competition, the computer vision subteam focused in on utilizing YOLO (You Only Look Once) algorithms. These are well-established and easy to use convolutional neural networks that accurately perform object detection and now have the ability to create segmentation masks as well (essentially highlight the "object" as a whole with its contours). In this project, you will learn how to train your own YOLO model and train its efficacy.


Follow [this Google Colab Notebook](https://colab.research.google.com/drive/1ldf6muZj2Lq2gcwi4KZ-4acTULx_L1k2?usp=sharing) to complete the project
  - Reference the resources below if you get stuck
    - [Optimizing your model]()
    - [Running the Notebook]()


Additional YOLO Resources:
1. Simple Python script to run YOLO model on real videos [here](./YOLOv8.py)
     - Training videos found [here](https://www.dropbox.com/scl/fo/ilsmrvomdx4h1tn74hw0g/AMsCjRdGOaHDy991yNH1SF8?rlkey=yuisarsyjqv0tj1tfrx263rdf&st=thucvkmj&dl=0)
3. Annotating a dataset from scratch in Roboflow [here]()
4. Simplified YOLOv8 Training Notebook [here](https://colab.research.google.com/drive/1fnNdFck-4ZVvTobmnYd679QCmJ9Nz6JC?usp=sharing)
